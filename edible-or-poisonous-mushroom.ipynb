{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"},{"sourceId":9244523,"sourceType":"datasetVersion","datasetId":5592284},{"sourceId":9244539,"sourceType":"datasetVersion","datasetId":5592293}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\nfrom matplotlib import pyplot as plt # data visualization\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-26T17:48:16.331096Z","iopub.execute_input":"2024-08-26T17:48:16.331496Z","iopub.status.idle":"2024-08-26T17:48:19.116423Z","shell.execute_reply.started":"2024-08-26T17:48:16.331461Z","shell.execute_reply":"2024-08-26T17:48:19.113984Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e8/sample_submission.csv\n/kaggle/input/playground-series-s4e8/train.csv\n/kaggle/input/playground-series-s4e8/test.csv\n/kaggle/input/cleaned-data/Mushroom train_data__Cleaned.csv\n/kaggle/input/cleaned-data/Mushroom test_data__Cleaned.csv\n/kaggle/input/tx-pipeline/tx_pipe.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"mdf = pd.read_csv(\"/kaggle/input/playground-series-s4e8/train.csv\")\nmdf_test = pd.read_csv(\"/kaggle/input/playground-series-s4e8/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T17:52:12.443053Z","iopub.execute_input":"2024-08-26T17:52:12.443444Z","iopub.status.idle":"2024-08-26T17:52:12.970654Z","shell.execute_reply.started":"2024-08-26T17:52:12.443416Z","shell.execute_reply":"2024-08-26T17:52:12.969518Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## **Knowing the Data:~**","metadata":{}},{"cell_type":"code","source":"mdf.set_index('id', inplace=True)\nmdf_test.set_index('id', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmbd_data = pd.concat([mdf,mdf_test])\ncmbd_data.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(mdf.columns)\ndisplay(mdf_test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.columns = mdf.columns.str.replace(\"-\", \"_\", regex=True)\nmdf.rename(columns={\"class\":\"e_label\"}, inplace=True)\n\nmdf_test.columns = mdf_test.columns.str.replace(\"-\", \"_\", regex=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf[mdf.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test[mdf_test.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### //- SUMMARY from above:\n* ##### The dataset has **22 columns**, with \"id\" column set as index. So effectively 21.\n* ##### There are **3116945 rows. No duplicate rows** in the train dataset. \n* ##### Test dataset has **2077964 rows, and 20 cols**. No duplicates here as well.\n* ##### Some of the columns have **a lot of null** values in both train & test data..\n* ##### **Target column name is \"e_label\"** meaning Edibility-label.","metadata":{}},{"cell_type":"markdown","source":"### **Details of the Numerical Columns:~**","metadata":{}},{"cell_type":"code","source":"mdf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\nfig.suptitle('Box Plots of --')\n\n# cap_diameter\nsns.boxplot(ax=axes[0], x=mdf[\"cap_diameter\"])\naxes[0].set_title(\"Cap Diameter\")\n\n# stem_height\nsns.boxplot(ax=axes[1], x=mdf[\"stem_height\"])\naxes[1].set_title(\"Stem Height\")\n\n# stem_width\nsns.boxplot(ax=axes[2], x=mdf[\"stem_width\"])\naxes[2].set_title(\"Stem Width\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(10, 4), sharey=True)\nfig.suptitle('Histplot of --')\n\n# cap_diameter\nsns.histplot(x=mdf[\"cap_diameter\"], ax=axes[0],kde=True, bins=15)\naxes[0].set_title(\"Cap Diameter\")\n\n# stem_height\nsns.histplot(x=mdf[\"stem_height\"], ax=axes[1],kde=True, bins=15)\naxes[1].set_title(\"Stem Height\")\n\n# stem_width\nsns.histplot(x=mdf[\"stem_width\"], ax=axes[2],kde=True, bins=15)\naxes[2].set_title(\"Stem Width\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Details of the Categorical Columns:~**","metadata":{}},{"cell_type":"code","source":"mdf.describe(include=\"object\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(mdf.e_label.value_counts())\nmdf.e_label.value_counts().plot(kind=\"pie\", title=\"Proportion of e & p\", ylabel=\"\",\n                                y=mdf.e_label.value_counts(), figsize=(4,4),\n                                autopct=\"%1.01f%%\", explode=(0.01,0.02))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.cap_shape.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.cap_shape.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### In cap_shape there are some garbage values, probably are wringly imputed. Let's check how much data are such.","metadata":{}},{"cell_type":"code","source":"mdf[mdf.cap_shape.isin(list(\"fxpbocsdenwkltgzaruyimh\")+[np.nan])].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So there are **(3116945-3116890) = 55** such data. We can remove these.","metadata":{}},{"cell_type":"code","source":"mdf = mdf[mdf.cap_shape.isin(list(\"fxpbocsdenwkltgzaruyimh\")+[np.nan])]\nsns.catplot(mdf, kind=\"count\", x =\"cap_shape\", height=3, aspect=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Proportion wise only 7 entries like **f,x,p,b,o,c,s have visible spread over the cap_shape series.**","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:19:16.282811Z","iopub.execute_input":"2024-08-12T06:19:16.283201Z","iopub.status.idle":"2024-08-12T06:19:24.568051Z","shell.execute_reply.started":"2024-08-12T06:19:16.283173Z","shell.execute_reply":"2024-08-12T06:19:24.566785Z"}}},{"cell_type":"code","source":"mdf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.cap_surface.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The same is for cap_surface too. So have done the same operation and dropped those garbage entries.","metadata":{}},{"cell_type":"code","source":"mdf = mdf[mdf.cap_surface.isin(list(\"shyltegdiwkfnroauzpbmxc\")+[np.nan])]\nsns.catplot(mdf, kind=\"count\", x =\"cap_surface\", height=3, aspect=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape #73 rows dropped in this process.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.cap_color.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf = mdf[mdf.cap_color.isin(list(\"uobgwneyrpklihdsafcxmzt\")+[np.nan])]\nsns.catplot(mdf, kind=\"count\", x =\"cap_color\", height=3, aspect=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape #72 records removed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.does_bruise_or_bleed.value_counts().head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The column name suggests that it should be a Binary column. Checked on the official website as well, which confirms the same as well. Hence kept only t & f, as in True and False.","metadata":{}},{"cell_type":"code","source":"mdf = mdf[mdf.does_bruise_or_bleed.isin(list(\"tf\"))]\nsns.catplot(data = mdf, x='does_bruise_or_bleed', kind=\"count\", height=3, aspect=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape #117 records dropped","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list('abcdefghijklmnopqrstuvwxyz')\natoz = [chr(i) for i in range(ord('a'), ord('z')+1)]\n\ndef non_alpha_categories_removal(df, col, atoz):\n    len_before = df.shape[0]\n    df = df[df[col].isin(atoz+[np.nan])]\n    len_after = df.shape[0]\n    print(f\"'{col}' processed. {len_before-len_after} records removed\")\n    sns.catplot(df, kind=\"count\", x =col, height=2, aspect=3)\n    return df\n\n\nfor col in ['gill_attachment', 'gill_spacing', 'gill_color',\n            'stem_root', 'stem_surface', 'stem_color', 'veil_type', \n            'veil_color', 'has_ring', 'ring_type', 'spore_print_color', 'habitat']:\n    mdf = non_alpha_categories_removal(mdf,col, atoz)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(mdf.season.value_counts())\nmdf.season.value_counts().plot(figsize=(7,4), kind=\"pie\", y=mdf.season.value_counts(),\n                              autopct = \"%1.01f%%\", title=\"Distribution of Season\", ylabel=\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### //- SUMMARY from above:\n1. ##### The **numerical columns have a lot of outliers.** Stem height column is normally distributed, while the others are right-skewed.\n2. ##### The **target column is almost equally distributed** among Edible and Poisonous\n3. ##### Most of the other **categorical columns had some garbage values** like numerical records or class name and so. So, have removed these garbage records **(about 700 rows dropped).** Still, *not all the alphabetical values are having significant spreads across respective columns.* So need to verify their correctness to decide whether to keep them or not.\n4. ##### About **4 Mushrooms in every 5 don't have bruising or bleeding.**\n5. ##### There are **4 different seasons** spreading across the dataset, which are most probably **\"Autumn\", \"Summer\", \"Winter\", and \"Spring\".** --> Spring occurs the least among all.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Cleaning & Processing:~**","metadata":{}},{"cell_type":"code","source":"temp = mdf.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mdf = temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Outlier Removal:**","metadata":{}},{"cell_type":"markdown","source":"#### Previuosly we had concluded that the numerical columns had good amount of outliers. Let's try to fix those now.","metadata":{}},{"cell_type":"code","source":"num_cols = ['cap_diameter', 'stem_height', 'stem_width']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(3, 2, figsize=(10, 6), sharey=True)\nfig.suptitle('-- Spread in Nuemrical columns -- ')\ncolor_map = ['#ec407a','#16a085', '#7986cb']\n\nfor n,col in enumerate(num_cols):\n    sns.boxplot(ax=axes[n][0], x=mdf[col], color=color_map[n])\n    axes[n][0].set_title(f\"Box Plot of {col}\", backgroundcolor='lightgrey')\n    axes[n][0].set_xlabel(\"\")\n    \n    sns.violinplot(ax=axes[n][1], x=mdf[col],  color=color_map[n])\n    axes[n][1].set_title(f\"Violin Plot of {col}\", backgroundcolor='lightgrey')\n    axes[n][1].set_xlabel(\"\")\n    \nfig.tight_layout()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Outlier Removal using IQR Method\n\nfor col in num_cols:\n    Q1 = mdf[col].quantile(.25)\n    Q3 = mdf[col].quantile(.75)\n    IQR = Q3-Q1\n    \n    LL = Q1-1.5*IQR\n    UL = Q3+1.5*IQR\n    print(f\"{mdf[(mdf[col]<LL) | (mdf[col]>UL)].shape[0]} rows are removed:\")\n    mdf = mdf[(mdf[col]>=LL) & (mdf[col]<=UL)]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(3, 2, figsize=(10, 6), sharey=True)\nfig.suptitle('-- Spread in Nuemrical columns -- ')\ncolor_map = ['#ec407a','#16a085', '#7986cb']\n\nfor n,col in enumerate(num_cols):\n    sns.boxplot(ax=axes[n][0], x=mdf[col], color=color_map[n])\n    axes[n][0].set_title(f\"Box Plot of {col}\", backgroundcolor='lightgrey')\n    axes[n][0].set_xlabel(\"\")\n    \n    sns.violinplot(ax=axes[n][1], x=mdf[col],  color=color_map[n])\n    axes[n][1].set_title(f\"Violin Plot of {col}\", backgroundcolor='lightgrey')\n    axes[n][1].set_xlabel(\"\")\n    \nfig.tight_layout()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Handling Null/ Missing Values:**","metadata":{}},{"cell_type":"code","source":"mdf.isnull().mean().round(4) * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(mdf.isnull().mean().round(4) * 100).plot.bar(title=\"Percentage of null values in each columns\",figsize=(12,3), color='brown')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So, from the above diagram, it's clear that a few columns like `\"stem_root\"`, `\"stem_surface\"`, `\"veil_type\"`, `\"veil_color\"`, and `\"spore_print_color\"` **has 60-96% data missing.** \n\n#### And, **we should not impute these many records**. \n> Logically, when there are more than 50% of data missing and there's no known reason of this, we should not fill in any values, and drop such columns. Because in that case more than half of things we are doing don't have any conclusive evidence of why we are doing.\n#### So we will remove this columns.\n","metadata":{}},{"cell_type":"code","source":"# Let's drop any columns that has more than 50% null value\nthreshold_na = len(mdf) * 0.50\n\n# Drop columns with more than 50% missing values\nmdf = mdf.dropna(thresh=threshold_na, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.sample(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Four other columns namely, `\"cap_surface\"`, `\"gill_attachment\"`, `\"gill_spacing\"` & `\"ring_type\"` has visible null amount. For now we can impute all missing values in these columns as \"unk\", as in \"Unknown\". \n#### Later on these columns can be judged based on correlation with target. ","metadata":{}},{"cell_type":"code","source":"mdf[[\"cap_surface\", \"gill_attachment\", \"gill_spacing\", \"ring_type\"]]=mdf[[\"cap_surface\", \"gill_attachment\", \"gill_spacing\", \"ring_type\"]].fillna(\"unk\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf[[\"cap_surface\", \"gill_attachment\", \"gill_spacing\", \"ring_type\"]].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.ring_type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As a result of the above operation, we have successfully handled most of the null values. Rest of the columns have very few null entries (near to 0%). We can drop these.","metadata":{}},{"cell_type":"code","source":"mdf.dropna(inplace=True)\nmdf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Removing unwanted/rare data:**","metadata":{}},{"cell_type":"code","source":"mdf.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Earlier we had seen than all these categorical columns have many unique values in them. And most of those have very low spread in the dataset. \n#### The above output shows that apart from the target column, three numerical columns & 2 other categorical columns, all other have more than 20 unique values. This much variation will confuse both us and our ML algo. \n####  \n\n#### What are we gonna do then? \n> Let's consider only those unique values that have atleast 5% spread in the respective columns. The rest of them might have been wrongly imputed or are rare. We can change those to `Other`","metadata":{}},{"cell_type":"code","source":"mdf.cap_shape.value_counts()/mdf.cap_shape.count()*100 #will consider till cap_shape='b', rest-->'other'\n\n#mdf.cap_shape.value_counts(normalize=True) yields the same","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_counts = mdf.cap_shape.value_counts()/mdf.cap_shape.count()*100\nidx = percent_counts[percent_counts<5].index\nprint(idx)\n\nmdf.loc[mdf.cap_shape.isin(idx), 'cap_shape'] = \"other\"\nprint(mdf.cap_shape.value_counts()/mdf.cap_shape.count()*100)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This makes the change as we indended for. But **if in any case, the percentage of 'other' too is less than 5%,** we can drop them.","metadata":{}},{"cell_type":"code","source":"for col in ['cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing', 'gill_color',\n            'stem_color', 'has_ring', 'ring_type', 'habitat']:\n\n    percent_counts = mdf[col].value_counts()/mdf[col].count()*100\n    idx = percent_counts[percent_counts<5].index\n\n    if percent_counts[percent_counts<5].sum()>=5:\n        mdf.loc[mdf[col].isin(idx), col] = \"other\"\n        print(f\"Rare categories in '{col}' column are classed as 'other'\")\n    \n    else:\n        mdf = mdf.loc[~mdf[col].isin(idx)]\n        print(f\"Rare categories in '{col}' column are dropped\")    \n    ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here's information on most frequest values of each categorical columns\n\n* **cap-shape (n):** bell=b, convex=x, flat=f, sunken=s,\n* **cap-color (n):** brown=n, gray=g, white=w, yellow=y, orange=o, red=e,\n* **does-bruise-or-bleed (n):** true=t,false=f,\n* **gill-spacing (n):** close=c, distant=d,\n* **gill-color (n):**  brown=n, white=w, gray=g, pink=p, yellow=y, orange=o,\n* **stem-color (n):**  brown=n, white=w, yellow=y, \n* **has-ring (n):** true=t, false=f,\n* **ring-type (n):** flaring=f,\n* **habitat (n):** grasses=g, leaves=l, meadows=m, woods=d,\n* **season (n):** spring=s, summer=u, autumn=a, winter=w","metadata":{}},{"cell_type":"code","source":"# Category name maping \n\nmdf.cap_shape = mdf.cap_shape.replace({'b':\"bell\", 'x':\"convex\", 'f':\"flat\", 's':\"sunken\"})\nmdf.cap_color = mdf.cap_color.replace({'n':\"brown\", 'g':\"gray\", 'w':\"white\", 'y':\"yellow\", 'o':\"orange\", 'e':\"red\"})\nmdf.gill_spacing = mdf.gill_spacing.replace({'c':\"close\", 'd':\"distant\"})\nmdf.gill_color = mdf.gill_color.replace({'n':\"brown\", 'g':\"gray\", 'w':\"white\", 'p':\"pink\", 'y':\"yellow\", 'o':\"orange\"})\nmdf.stem_color = mdf.stem_color.replace({'n':\"brown\", 'w':\"white\", 'y':\"yellow\"})\nmdf.ring_type = mdf.ring_type.replace({'f':\"flaring\"})\nmdf.habitat = mdf.habitat.replace({'g':\"grasses\", 'l':\"leaves\", 'm':\"meadows\", 'd':\"woods\"})\nmdf.season = mdf.season.replace({'s':\"spring\", 'u':\"summer\", 'w':\"winter\", 'a':\"autumn\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.sample(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols= ['cap_shape', 'cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing', 'gill_color', \n                   'stem_color', 'has_ring', 'ring_type', 'does_bruise_or_bleed', 'habitat', 'season' ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in categorical_cols:\n    print(mdf[col].value_counts(normalize=True))\n    print(\"============================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = np.reshape(categorical_cols, (4,3))\n\n# for col in categorical_cols:\nf, axs = plt.subplots(4, 3, figsize=(18, 15))\n\nfor n, col in enumerate(cat_cols):\n    sns.countplot(ax=axs[n,0], data=mdf, x =col[0])\n    axs[n,0].set_title(f\"Freq. of each category in {col[0]}\")\n    axs[n,0].set_xlabel(\"\")\n    axs[n,0].set_ylabel(\"\")\n    \n    sns.countplot(ax=axs[n,1], data=mdf, x =col[1])\n    axs[n,1].set_title(f\"Freq. of each category in {col[1]}\")\n    axs[n,1].set_xlabel(\"\")\n    axs[n,1].set_ylabel(\"\")\n    \n    sns.countplot(ax=axs[n,2], data=mdf, x =col[2])\n    axs[n,2].set_title(f\"Freq. of each category in {col[2]}\")\n    axs[n,2].set_xlabel(\"\")\n    axs[n,2].set_ylabel(\"\")\n\nf.tight_layout()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### //- SUMMARY from above:\n1. ##### Outliers from the numerical columns are removed. **Around 2.5 lac records (~ 8% of whole) dropped.**\n2. ##### **\"stem_root\", \"stem_surface\", \"veil_type\", \"veil_color\", and \"spore_print_color\"** columns had more than 50% null values. Hence those columns were *dropped.* \n3. ##### Null values in **\"cap_surface\", \"gill_attachment\", \"gill_spacing\" & \"ring_type\"** columns were *imputed with \"unk\" as in \"Unknown\".*\n4. ##### In other categorical columns... *only those categories are kept that had a **spread of 5% or more** in the respective columns. If not, all are combined to form a new category as \"Other\".*\n5. ##### **Categories were replaced with their more convenient names** with reference from original website.\n6. ##### As of now there are **16 columns** *(1 target column, 3 Numerical ones, 3 binary & rest of those are nominal ones)*. Around **27.5 lac rows present.**","metadata":{"execution":{"iopub.status.busy":"2024-08-22T06:35:12.600715Z","iopub.status.idle":"2024-08-22T06:35:12.601098Z","shell.execute_reply.started":"2024-08-22T06:35:12.600898Z","shell.execute_reply":"2024-08-22T06:35:12.600914Z"}}},{"cell_type":"markdown","source":"### **Bi-variate & Multivariate Analysis:**","metadata":{}},{"cell_type":"code","source":"mdf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data =mdf, fill=True, x='cap_diameter', hue='e_label')\nprint(\"Mushrooms with less cap diameter have a higher chance of being Poisonous.\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(kind='box', data =mdf, x='e_label', y='cap_diameter', hue='season', height=3, aspect=2)\nprint(\"Mushrooms is Spring season are mostly smaller in cap diameter.\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(kind='box', data =mdf, x='e_label', y='cap_diameter', hue='habitat', height=3, aspect=2)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data =mdf, kind='kde', x='stem_height', hue='e_label', height=3, aspect=2)\nprint(\"Mostly mushrooms' stems are between 4-8 cm tall, with equal probability of e&p\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(kind='box', data =mdf, x='e_label', y='stem_height', hue='season', height=3, aspect=2)\nprint(\"Stem heights are almost constant across different seasons, and edibility.\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(kind='box', data =mdf, x='e_label', y='stem_height', hue='habitat', height=3, aspect=2)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data =mdf, x='stem_width', hue='e_label', height=3, aspect=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data =mdf, kind='kde', x='stem_width', hue='e_label', height=3, aspect=2)\nprint(\"The narrower Mushrooms tend to be more poisonous.\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(kind='box', data =mdf, x='e_label', y='stem_width', hue='season', height=3, aspect=2)\nprint(\"Mushrooms growing in Spring season are comparatively much narrower.\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(kind='box', data =mdf, x='e_label', y='stem_width', hue='habitat', height=3, aspect=2)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = np.reshape(categorical_cols, (4,3))\n\n# for col in categorical_cols:\nf, axs = plt.subplots(4, 3, figsize=(15, 15))\nf.suptitle('-- \"e_label\" proportion in each Categorical columns -- ', fontsize=17)\nc_palette={'e':'#18ac8f', 'p':'#e5306d'}\n\nfor n, col in enumerate(cat_cols):\n    sns.histplot(ax=axs[n,0], data=mdf, x =col[0], hue='e_label', multiple='stack', palette=c_palette)\n    sns.histplot(ax=axs[n,1], data=mdf, x =col[1], hue='e_label', multiple='fill', palette=c_palette)\n    sns.histplot(ax=axs[n,2], data=mdf, x =col[2], hue='e_label', multiple='fill', palette=c_palette)\n\n    \nprint(\"-- Be remindful of these before eating or buying Mushrooms --\",\"\\n============================================\")    \nprint(\"* Mushrooms with bell-shaped cap are more like to be poisonous, others have about 50% possibility.\")\nprint(\"* Mushrooms with red or orange coloured cap should better be avoided.\")\nprint(\"* White stem Mushrooms can be eaten, but be cautious that those ain't towards the yellowish side.\")\nprint(\"* Mushrooms growing in grass or meadows are more likely to be poisonous. The ones in woods & leaves are a better choice.\")\nprint(\"* You can better eat mushrooms of Winters. Otherwise there 50-50 between e & p.\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The target column is well-balanced, as we have seen at the begining. So we don't need to bother about Sampling. So that's it with EDA. ","metadata":{}},{"cell_type":"markdown","source":"#### Let's sum up the main steps we have executed, as the same need to be done for the test data as well.\n1. **Removing the non-alphabetical (noisy) categories** from the Categorical columns\n2. **Keep only t&f** for `does_bruise_or_bleed` column\n3. **Outlier removal**\n4. **Null Value Handling~**\n    * **Dropping columns with more than 50% null entries.**\n    * **Impute 'unk' for other columns** with 10-50% null. \n    * **Drop rows for NA entries in other cols**\n5. **Removing unwanted/rare data**","metadata":{}},{"cell_type":"code","source":"#1 Removing the non-alphabetical (noisy) categories\n\nfor col in ['cap_shape', 'cap_surface', 'cap_color', 'gill_attachment', 'gill_spacing',\n            'gill_color', 'stem_root', 'stem_surface', 'stem_color', 'veil_type', \n            'veil_color', 'has_ring', 'ring_type', 'spore_print_color', 'habitat']:\n\n    mdf_test = non_alpha_categories_removal(mdf_test, col, atoz)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test.season.value_counts().plot(figsize=(5,3), kind=\"pie\", y=mdf_test.season.value_counts(),\n                              autopct = \"%1.01f%%\", title=\"Distribution of Season\", ylabel=\"\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2 Keep only t&f for does_bruise_or_bleed\n\nmdf_test = mdf_test[mdf_test.does_bruise_or_bleed.isin(list(\"tf\"))]\n\nmdf_test.does_bruise_or_bleed.value_counts().plot(figsize=(5,3), kind=\"pie\", y=mdf_test.does_bruise_or_bleed.value_counts(),\n                              autopct = \"%1.01f%%\", title=\"Home many with Bruises/bleedings?\", ylabel=\"\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#3 Outlier Removal using IQR Method\n\nfor col in num_cols:\n    Q1 = mdf_test[col].quantile(.25)\n    Q3 = mdf_test[col].quantile(.75)\n    IQR = Q3-Q1\n    \n    LL = Q1-1.5*IQR\n    UL = Q3+1.5*IQR\n    print(f\"{mdf_test[(mdf_test[col]<LL) | (mdf_test[col]>UL)].shape[0]} rows are removed:\")\n    mdf_test = mdf_test[(mdf_test[col]>=LL) & (mdf_test[col]<=UL)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(3, 2, figsize=(10, 6), sharey=True)\nfig.suptitle('-- Spread in Nuemrical columns -- ')\ncolor_map = ['#7d57b0','#de513b', '#7dd137']\n\nfor n,col in enumerate(num_cols):\n    sns.boxplot(ax=axes[n][0], x=mdf_test[col], color=color_map[n])\n    axes[n][0].set_title(f\"Box Plot of {col}\", backgroundcolor='lightgrey')\n    axes[n][0].set_xlabel(\"\")\n    \n    sns.violinplot(ax=axes[n][1], x=mdf_test[col],  color=color_map[n])\n    axes[n][1].set_title(f\"Violin Plot of {col}\", backgroundcolor='lightgrey')\n    axes[n][1].set_xlabel(\"\")\n    \nfig.tight_layout()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#4 Null Handling\n\n(mdf_test.isnull().mean().round(4) * 100).plot.bar(title=\"Percentage of null values in each columns\",figsize=(12,3), color='brown')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_na = len(mdf_test) * 0.50\n\n# Drop columns with more than 50% missing values\nmdf_test = mdf_test.dropna(thresh=threshold_na, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test[[\"cap_surface\", \"gill_attachment\", \"gill_spacing\", \"ring_type\"]]=mdf_test[[\"cap_surface\", \"gill_attachment\", \"gill_spacing\", \"ring_type\"]].fillna(\"unk\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test.dropna(inplace=True)\nmdf_test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#5 Removing unwanted/rare data\n## Instead using replace, as earlier, we will use map now. \n## This would make any other categories mapped to null, which we can later be changed to \"Other\"\n\nmdf_test.cap_shape = mdf_test.cap_shape.map({'b':\"bell\", 'x':\"convex\", 'f':\"flat\", 's':\"sunken\"})\nmdf_test.cap_color = mdf_test.cap_color.map({'n':\"brown\", 'g':\"gray\", 'w':\"white\", 'y':\"yellow\", 'o':\"orange\", 'e':\"red\"})\nmdf_test.gill_spacing = mdf_test.gill_spacing.map({'c':\"close\", 'd':\"distant\", \"unk\":\"unk\"})\nmdf_test.gill_color = mdf_test.gill_color.map({'n':\"brown\", 'g':\"gray\", 'w':\"white\", 'p':\"pink\", 'y':\"yellow\", 'o':\"orange\"})\nmdf_test.stem_color = mdf_test.stem_color.map({'n':\"brown\", 'w':\"white\", 'y':\"yellow\"})\nmdf_test.ring_type = mdf_test.ring_type.map({'f':\"flaring\"})\nmdf_test.habitat = mdf_test.habitat.map({'g':\"grasses\", 'l':\"leaves\", 'm':\"meadows\", 'd':\"woods\"})\nmdf_test.season = mdf_test.season.map({'s':\"spring\", 'u':\"summer\", 'w':\"winter\", 'a':\"autumn\"})\n\n#for other columns (matched with train data)\nmdf_test.cap_surface = np.where(mdf_test.cap_surface.isin(['s','h','y','t','g','d','unk']),mdf_test.cap_surface, \"other\")\nmdf_test = mdf_test[mdf_test.gill_attachment.isin(['s','a','x','d','e','p','unk'])]\nmdf_test = mdf_test[mdf_test.has_ring.isin(['t','f'])]\n\nmdf_test.dropna(subset = ['gill_spacing'], inplace=True)  #'other' is not there in gill_spacing for mdf, hence NAs ain't kept to be filled.\nmdf_test.fillna(\"other\", inplace=True)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in categorical_cols:\n    print(mdf_test[col].value_counts(normalize=True))\n    print(\"============================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mdf.nunique(),\"\\n=======================\")\nprint(mdf_test.nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = np.reshape(categorical_cols, (4,3))\n\n# for col in categorical_cols:\nf, axs = plt.subplots(4, 3, figsize=(18, 15))\nf.suptitle('-- Distribution in mdf_test data -- ', fontsize=17)\n\nfor n, col in enumerate(cat_cols):\n    sns.countplot(ax=axs[n,0], data=mdf_test, x =col[0])\n    axs[n,0].set_title(f\"Freq. of each category in {col[0]}\")\n    axs[n,0].set_xlabel(\"\")\n    axs[n,0].set_ylabel(\"\")\n    \n    sns.countplot(ax=axs[n,1], data=mdf_test, x =col[1])\n    axs[n,1].set_title(f\"Freq. of each category in {col[1]}\")\n    axs[n,1].set_xlabel(\"\")\n    axs[n,1].set_ylabel(\"\")\n    \n    sns.countplot(ax=axs[n,2], data=mdf_test, x =col[2])\n    axs[n,2].set_title(f\"Freq. of each category in {col[2]}\")\n    axs[n,2].set_xlabel(\"\")\n    axs[n,2].set_ylabel(\"\")\n\nf.tight_layout()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We are now all good to prepare our data from model building. That includes:--\n* Encoding Categorical cols\n* Standardizing cell values\n##### So before we start that, **let's split the mdf dataset into train & test data,** to prevent *data-leakage.*\n\n##### Saving this cleaned train & test data, for future needs ~~~","metadata":{}},{"cell_type":"code","source":"mdf.to_csv(\"Mushroom train_data__Cleaned.csv\")\nmdf_test.to_csv(\"Mushroom test_data__Cleaned.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf = pd.read_csv('/kaggle/input/cleaned-data/Mushroom train_data__Cleaned.csv')\nmdf_test = pd.read_csv('/kaggle/input/cleaned-data/Mushroom test_data__Cleaned.csv')\n\nmdf.set_index('id', inplace=True)\nmdf_test.set_index('id', inplace=True)\nmdf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:49:01.468074Z","iopub.execute_input":"2024-08-26T18:49:01.468478Z","iopub.status.idle":"2024-08-26T18:49:13.279409Z","shell.execute_reply.started":"2024-08-26T18:49:01.468449Z","shell.execute_reply":"2024-08-26T18:49:13.278233Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"   e_label  cap_diameter cap_shape cap_surface cap_color does_bruise_or_bleed  \\\nid                                                                              \n0        e          8.80      flat           s     other                    f   \n1        p          4.51    convex           h    orange                    f   \n2        e          6.94      flat           s     other                    f   \n3        e          3.88      flat           y      gray                    f   \n4        e          5.85    convex       other     white                    f   \n\n   gill_attachment gill_spacing gill_color  stem_height  stem_width  \\\nid                                                                    \n0                a        close      white         4.51       15.39   \n1                a        close      brown         4.79        6.48   \n2                x        close      white         6.85        9.93   \n3                s          unk       gray         4.16        6.53   \n4                d          unk      white         3.37        8.36   \n\n   stem_color has_ring ring_type  habitat  season  \nid                                                 \n0       white        f   flaring    woods  autumn  \n1       other        t     other    woods  winter  \n2       brown        f   flaring   leaves  winter  \n3       white        f   flaring    woods  summer  \n4       white        f   flaring  grasses  autumn  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>e_label</th>\n      <th>cap_diameter</th>\n      <th>cap_shape</th>\n      <th>cap_surface</th>\n      <th>cap_color</th>\n      <th>does_bruise_or_bleed</th>\n      <th>gill_attachment</th>\n      <th>gill_spacing</th>\n      <th>gill_color</th>\n      <th>stem_height</th>\n      <th>stem_width</th>\n      <th>stem_color</th>\n      <th>has_ring</th>\n      <th>ring_type</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e</td>\n      <td>8.80</td>\n      <td>flat</td>\n      <td>s</td>\n      <td>other</td>\n      <td>f</td>\n      <td>a</td>\n      <td>close</td>\n      <td>white</td>\n      <td>4.51</td>\n      <td>15.39</td>\n      <td>white</td>\n      <td>f</td>\n      <td>flaring</td>\n      <td>woods</td>\n      <td>autumn</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>p</td>\n      <td>4.51</td>\n      <td>convex</td>\n      <td>h</td>\n      <td>orange</td>\n      <td>f</td>\n      <td>a</td>\n      <td>close</td>\n      <td>brown</td>\n      <td>4.79</td>\n      <td>6.48</td>\n      <td>other</td>\n      <td>t</td>\n      <td>other</td>\n      <td>woods</td>\n      <td>winter</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e</td>\n      <td>6.94</td>\n      <td>flat</td>\n      <td>s</td>\n      <td>other</td>\n      <td>f</td>\n      <td>x</td>\n      <td>close</td>\n      <td>white</td>\n      <td>6.85</td>\n      <td>9.93</td>\n      <td>brown</td>\n      <td>f</td>\n      <td>flaring</td>\n      <td>leaves</td>\n      <td>winter</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e</td>\n      <td>3.88</td>\n      <td>flat</td>\n      <td>y</td>\n      <td>gray</td>\n      <td>f</td>\n      <td>s</td>\n      <td>unk</td>\n      <td>gray</td>\n      <td>4.16</td>\n      <td>6.53</td>\n      <td>white</td>\n      <td>f</td>\n      <td>flaring</td>\n      <td>woods</td>\n      <td>summer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e</td>\n      <td>5.85</td>\n      <td>convex</td>\n      <td>other</td>\n      <td>white</td>\n      <td>f</td>\n      <td>d</td>\n      <td>unk</td>\n      <td>white</td>\n      <td>3.37</td>\n      <td>8.36</td>\n      <td>white</td>\n      <td>f</td>\n      <td>flaring</td>\n      <td>grasses</td>\n      <td>autumn</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mdf = mdf[['e_label','cap_diameter','stem_height','stem_width','cap_shape','cap_surface','cap_color','does_bruise_or_bleed','gill_attachment','gill_spacing','gill_color','stem_color','has_ring','ring_type','habitat','season']]\nmdf_test = mdf_test[['cap_diameter','stem_height','stem_width','cap_shape','cap_surface','cap_color','does_bruise_or_bleed','gill_attachment','gill_spacing','gill_color','stem_color','has_ring','ring_type','habitat','season']]","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:49:16.963598Z","iopub.execute_input":"2024-08-26T18:49:16.964005Z","iopub.status.idle":"2024-08-26T18:49:17.690017Z","shell.execute_reply.started":"2024-08-26T18:49:16.963975Z","shell.execute_reply":"2024-08-26T18:49:17.688710Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"test_idx = mdf_test.index","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:49:24.356296Z","iopub.execute_input":"2024-08-26T18:49:24.356694Z","iopub.status.idle":"2024-08-26T18:49:24.362116Z","shell.execute_reply.started":"2024-08-26T18:49:24.356663Z","shell.execute_reply":"2024-08-26T18:49:24.360852Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmdf_X = mdf.iloc[:,1:]\nmdf_Y = mdf['e_label'].map({'e':1, 'p':0}) #a few of our models we will use to predict edibility, \n                                           #requires numerical labels. Hence converting to 1 & 0\n\n\nmdf_Xtrain, mdf_Xtest, mdf_Ytrain, mdf_Ytest = train_test_split(mdf_X, mdf_Y, test_size=0.3, random_state=25)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:00:01.882336Z","iopub.execute_input":"2024-08-26T18:00:01.882846Z","iopub.status.idle":"2024-08-26T18:00:07.031246Z","shell.execute_reply.started":"2024-08-26T18:00:01.882808Z","shell.execute_reply":"2024-08-26T18:00:07.030002Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"mdf_Ytrain","metadata":{"execution":{"iopub.status.busy":"2024-08-26T17:57:15.453723Z","iopub.execute_input":"2024-08-26T17:57:15.454136Z","iopub.status.idle":"2024-08-26T17:57:15.464281Z","shell.execute_reply.started":"2024-08-26T17:57:15.454104Z","shell.execute_reply":"2024-08-26T17:57:15.462974Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"id\n1498569    1\n2633402    1\n2124754    1\n854815     0\n2570868    0\n          ..\n928997     0\n2517394    1\n3067465    1\n1192165    0\n33810      0\nName: e_label, Length: 1930303, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2024-08-26T17:57:15.465865Z","iopub.execute_input":"2024-08-26T17:57:15.467070Z","iopub.status.idle":"2024-08-26T17:57:15.491846Z","shell.execute_reply.started":"2024-08-26T17:57:15.467020Z","shell.execute_reply":"2024-08-26T17:57:15.490544Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ad = mdf_Xtrain.iloc[:1000, :] #a test data, with 100 rows from mdf_Xtrain\n\n# testing to see how many rows occur.\nencoder = OneHotEncoder(sparse=False, handle_unknown='ignore', drop='first')\nad_t = encoder.fit_transform(ad.iloc[:,3:])\n\nad_t.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:04:23.154780Z","iopub.execute_input":"2024-08-26T18:04:23.155207Z","iopub.status.idle":"2024-08-26T18:04:23.178810Z","shell.execute_reply.started":"2024-08-26T18:04:23.155175Z","shell.execute_reply":"2024-08-26T18:04:23.177510Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(1000, 44)"},"metadata":{}}]},{"cell_type":"code","source":"#One Hot Encoding -----> after encoding, with drop=first, there will be total 44 encoded columns + the 3 numerical cols\n\nencoder = ColumnTransformer([\n    (\"ohe\", OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'),slice(3,15))\n],remainder='passthrough')\n\n\n#MinMax Scaling\n\nscaler = ColumnTransformer([\n    ('mmScaler',MinMaxScaler(),slice(0,47))\n],remainder='passthrough')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-08-26T18:04:57.775680Z","iopub.execute_input":"2024-08-26T18:04:57.776080Z","iopub.status.idle":"2024-08-26T18:04:57.782657Z","shell.execute_reply.started":"2024-08-26T18:04:57.776049Z","shell.execute_reply":"2024-08-26T18:04:57.781473Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"pipe = Pipeline([\n    (\"one_hot_encoder\", encoder),\n    (\"min_max_Scaler\", scaler)\n])\n\npipe.fit(mdf_Xtrain)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:04:58.535335Z","iopub.execute_input":"2024-08-26T18:04:58.535769Z","iopub.status.idle":"2024-08-26T18:05:10.001973Z","shell.execute_reply.started":"2024-08-26T18:04:58.535734Z","shell.execute_reply":"2024-08-26T18:05:10.000842Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('one_hot_encoder',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('ohe',\n                                                  OneHotEncoder(drop='first',\n                                                                handle_unknown='ignore',\n                                                                sparse=False),\n                                                  slice(3, 15, None))])),\n                ('min_max_Scaler',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('mmScaler', MinMaxScaler(),\n                                                  slice(0, 47, None))]))])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;one_hot_encoder&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;ohe&#x27;,\n                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                handle_unknown=&#x27;ignore&#x27;,\n                                                                sparse=False),\n                                                  slice(3, 15, None))])),\n                (&#x27;min_max_Scaler&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;mmScaler&#x27;, MinMaxScaler(),\n                                                  slice(0, 47, None))]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;one_hot_encoder&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;ohe&#x27;,\n                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                handle_unknown=&#x27;ignore&#x27;,\n                                                                sparse=False),\n                                                  slice(3, 15, None))])),\n                (&#x27;min_max_Scaler&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;mmScaler&#x27;, MinMaxScaler(),\n                                                  slice(0, 47, None))]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encoder: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;ohe&#x27;,\n                                 OneHotEncoder(drop=&#x27;first&#x27;,\n                                               handle_unknown=&#x27;ignore&#x27;,\n                                               sparse=False),\n                                 slice(3, 15, None))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>slice(3, 15, None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;cap_diameter&#x27;, &#x27;stem_height&#x27;, &#x27;stem_width&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">min_max_Scaler: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;mmScaler&#x27;, MinMaxScaler(),\n                                 slice(0, 47, None))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">mmScaler</label><div class=\"sk-toggleable__content\"><pre>slice(0, 47, None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"mdf_Xtrain = pipe.fit_transform(mdf_Xtrain)\nmdf_Xtest = pipe.fit_transform(mdf_Xtest)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:05:10.004142Z","iopub.execute_input":"2024-08-26T18:05:10.004485Z","iopub.status.idle":"2024-08-26T18:05:25.964820Z","shell.execute_reply.started":"2024-08-26T18:05:10.004457Z","shell.execute_reply":"2024-08-26T18:05:25.963537Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(f\"Shape of mdf_Xtrain array: {mdf_Xtrain.shape}\")\nprint(f\"Shape of mdf_Xtest array: {mdf_Xtest.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:05:25.966219Z","iopub.execute_input":"2024-08-26T18:05:25.966692Z","iopub.status.idle":"2024-08-26T18:05:25.973135Z","shell.execute_reply.started":"2024-08-26T18:05:25.966628Z","shell.execute_reply":"2024-08-26T18:05:25.971544Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Shape of mdf_Xtrain array: (1930303, 47)\nShape of mdf_Xtest array: (827273, 47)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Shape of mdf_Ytrain array: {mdf_Ytrain.shape}\")\nprint(f\"Shape of mdf_Ytest array: {mdf_Ytest.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:05:25.975548Z","iopub.execute_input":"2024-08-26T18:05:25.976031Z","iopub.status.idle":"2024-08-26T18:05:25.994815Z","shell.execute_reply.started":"2024-08-26T18:05:25.975995Z","shell.execute_reply":"2024-08-26T18:05:25.993490Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Shape of mdf_Ytrain array: (1930303,)\nShape of mdf_Ytest array: (827273,)\n","output_type":"stream"}]},{"cell_type":"code","source":"pipe.named_steps.one_hot_encoder.transformers_[0][1].get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T11:56:30.768792Z","iopub.execute_input":"2024-08-26T11:56:30.769086Z","iopub.status.idle":"2024-08-26T11:56:30.779988Z","shell.execute_reply.started":"2024-08-26T11:56:30.769055Z","shell.execute_reply":"2024-08-26T11:56:30.778971Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"array(['cap_shape_convex', 'cap_shape_flat', 'cap_shape_other',\n       'cap_shape_sunken', 'cap_surface_g', 'cap_surface_h',\n       'cap_surface_other', 'cap_surface_s', 'cap_surface_t',\n       'cap_surface_unk', 'cap_surface_y', 'cap_color_gray',\n       'cap_color_orange', 'cap_color_other', 'cap_color_red',\n       'cap_color_white', 'cap_color_yellow', 'does_bruise_or_bleed_t',\n       'gill_attachment_d', 'gill_attachment_e', 'gill_attachment_p',\n       'gill_attachment_s', 'gill_attachment_unk', 'gill_attachment_x',\n       'gill_spacing_distant', 'gill_spacing_unk', 'gill_color_gray',\n       'gill_color_orange', 'gill_color_other', 'gill_color_pink',\n       'gill_color_white', 'gill_color_yellow', 'stem_color_other',\n       'stem_color_white', 'stem_color_yellow', 'has_ring_t',\n       'ring_type_other', 'habitat_leaves', 'habitat_meadows',\n       'habitat_other', 'habitat_woods', 'season_spring', 'season_summer',\n       'season_winter'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Let's save the Pipiline as well, using **Pickle library.**","metadata":{}},{"cell_type":"code","source":"import pickle\n\n#creating a pickle file of my pipe.\n# pickle.dump(pipe, open('tx_pipe.pkl', 'wb'))\n\n# loading pickled pipeline \ntx_pipe = pickle.load(open('/kaggle/input/tx-pipeline/tx_pipe.pkl', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2024-08-26T11:56:30.781254Z","iopub.execute_input":"2024-08-26T11:56:30.781571Z","iopub.status.idle":"2024-08-26T11:56:30.791570Z","shell.execute_reply.started":"2024-08-26T11:56:30.781545Z","shell.execute_reply":"2024-08-26T11:56:30.790493Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# original test data\nmdf_test = pipe.fit_transform(mdf_test)\nprint(f\"Shape of mdf_test array: {mdf_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:05:30.868594Z","iopub.execute_input":"2024-08-26T18:05:30.869201Z","iopub.status.idle":"2024-08-26T18:05:41.625007Z","shell.execute_reply.started":"2024-08-26T18:05:30.869159Z","shell.execute_reply":"2024-08-26T18:05:41.623602Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Shape of mdf_test array: (1838614, 47)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Model Building:**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:05:45.953828Z","iopub.execute_input":"2024-08-26T18:05:45.954250Z","iopub.status.idle":"2024-08-26T18:05:46.481719Z","shell.execute_reply.started":"2024-08-26T18:05:45.954216Z","shell.execute_reply":"2024-08-26T18:05:46.480171Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression(random_state=2, solver='newton-cholesky')\ndt = DecisionTreeClassifier(random_state=3, max_features=25)\nrf = RandomForestClassifier(random_state=0, n_estimators=25, max_features = 20)\ngnb = GaussianNB()\ngbc = GradientBoostingClassifier(random_state=1, n_estimators=25)\nxgb = XGBClassifier()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:07:31.662682Z","iopub.execute_input":"2024-08-26T18:07:31.663144Z","iopub.status.idle":"2024-08-26T18:07:31.670017Z","shell.execute_reply.started":"2024-08-26T18:07:31.663112Z","shell.execute_reply":"2024-08-26T18:07:31.668595Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import time\n\nmodel_report = pd.DataFrame(columns = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"Time taken\"])\n\nmodels = [lr,dt,rf,gnb,gbc,xgb]\nmodel_names = [\"Logistic Regression\", \"Decision Tree Clf\", \"Random Forest Clf\", \"Gaussian Naive Bayes\", \"GB Clf\", \"XGB Clf\"]\n\nfor i, model in enumerate(models):\n    \n    start = time.time()\n    \n    model.fit(mdf_Xtrain,mdf_Ytrain)\n    print(f\"'{model_names[i]}' is ready to predict:~ \")\n    mdf_Ypred = model.predict(mdf_Xtest)\n    \n    time_taken = time.time()-start\n    \n    acc = accuracy_score(mdf_Ytest, mdf_Ypred)\n    p = precision_score(mdf_Ytest, mdf_Ypred, average='weighted')\n    r = recall_score(mdf_Ytest, mdf_Ypred, average='weighted')\n    f = f1_score(mdf_Ytest, mdf_Ypred, average='weighted')\n    print(\"Classification Reports:-\\n\", classification_report(mdf_Ytest, mdf_Ypred))\n    print(\"\\nConfusion Matrix:-\\n\", confusion_matrix(mdf_Ytest, mdf_Ypred))\n    \n    model_report = pd.concat([model_report, pd.DataFrame([{'accuracy':acc, 'precision':p, 'recall':r, 'f1':f, \"Time taken\":time_taken}])])\n    print(f\"Report of '{model_names[i]}' is recorded.\", \"\\n========================\")\n\nmodel_report[\"model\"] = model_names\nmodel_report = model_report[[\"model\",\"accuracy\", \"precision\", \"recall\", \"f1\", \"Time taken\"]]","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:12:52.630522Z","iopub.execute_input":"2024-08-26T18:12:52.633231Z","iopub.status.idle":"2024-08-26T18:25:27.850817Z","shell.execute_reply.started":"2024-08-26T18:12:52.633135Z","shell.execute_reply":"2024-08-26T18:25:27.848904Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Logistic Regression is ready to predict:~ \nClassification Reports:-\n               precision    recall  f1-score   support\n\n           0       0.79      0.77      0.78    449924\n           1       0.73      0.75      0.74    377349\n\n    accuracy                           0.76    827273\n   macro avg       0.76      0.76      0.76    827273\nweighted avg       0.76      0.76      0.76    827273\n\n\nConfusion Matrix:-\n [[346601 103323]\n [ 94794 282555]]\nReport of Logistic Regression is recorded. \n========================\nDecision Tree Clf is ready to predict:~ \nClassification Reports:-\n               precision    recall  f1-score   support\n\n           0       0.98      0.98      0.98    449924\n           1       0.98      0.98      0.98    377349\n\n    accuracy                           0.98    827273\n   macro avg       0.98      0.98      0.98    827273\nweighted avg       0.98      0.98      0.98    827273\n\n\nConfusion Matrix:-\n [[442699   7225]\n [  7160 370189]]\nReport of Decision Tree Clf is recorded. \n========================\nRandom Forest Clf is ready to predict:~ \nClassification Reports:-\n               precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99    449924\n           1       0.99      0.99      0.99    377349\n\n    accuracy                           0.99    827273\n   macro avg       0.99      0.99      0.99    827273\nweighted avg       0.99      0.99      0.99    827273\n\n\nConfusion Matrix:-\n [[445788   4136]\n [  3270 374079]]\nReport of Random Forest Clf is recorded. \n========================\nGaussian Naive Bayes is ready to predict:~ \nClassification Reports:-\n               precision    recall  f1-score   support\n\n           0       0.74      0.71      0.72    449924\n           1       0.67      0.71      0.69    377349\n\n    accuracy                           0.71    827273\n   macro avg       0.71      0.71      0.71    827273\nweighted avg       0.71      0.71      0.71    827273\n\n\nConfusion Matrix:-\n [[318414 131510]\n [110855 266494]]\nReport of Gaussian Naive Bayes is recorded. \n========================\nGB Clf is ready to predict:~ \nClassification Reports:-\n               precision    recall  f1-score   support\n\n           0       0.84      0.94      0.88    449924\n           1       0.91      0.78      0.84    377349\n\n    accuracy                           0.87    827273\n   macro avg       0.87      0.86      0.86    827273\nweighted avg       0.87      0.87      0.87    827273\n\n\nConfusion Matrix:-\n [[421841  28083]\n [ 82396 294953]]\nReport of GB Clf is recorded. \n========================\nXGB Clf is ready to predict:~ \nClassification Reports:-\n               precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99    449924\n           1       0.99      0.99      0.99    377349\n\n    accuracy                           0.99    827273\n   macro avg       0.99      0.99      0.99    827273\nweighted avg       0.99      0.99      0.99    827273\n\n\nConfusion Matrix:-\n [[445559   4365]\n [  3608 373741]]\nReport of XGB Clf is recorded. \n========================\n","output_type":"stream"}]},{"cell_type":"code","source":"model_report","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:27:48.617655Z","iopub.execute_input":"2024-08-26T18:27:48.618164Z","iopub.status.idle":"2024-08-26T18:27:48.635965Z","shell.execute_reply.started":"2024-08-26T18:27:48.618128Z","shell.execute_reply":"2024-08-26T18:27:48.634723Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                  model  accuracy  precision    recall        f1  Time taken\n0   Logistic Regression  0.760518   0.761064  0.760518  0.760710    7.219208\n0     Decision Tree Clf  0.982612   0.982612  0.982612  0.982612   37.780317\n0     Random Forest Clf  0.991048   0.991052  0.991048  0.991049  468.157669\n0  Gaussian Naive Bayes  0.707031   0.708834  0.707031  0.707492    2.469409\n0                GB Clf  0.866454   0.871475  0.866454  0.865077  190.281051\n0               XGB Clf  0.990362   0.990366  0.990362  0.990363   29.083586","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>Time taken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>0.760518</td>\n      <td>0.761064</td>\n      <td>0.760518</td>\n      <td>0.760710</td>\n      <td>7.219208</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Decision Tree Clf</td>\n      <td>0.982612</td>\n      <td>0.982612</td>\n      <td>0.982612</td>\n      <td>0.982612</td>\n      <td>37.780317</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Random Forest Clf</td>\n      <td>0.991048</td>\n      <td>0.991052</td>\n      <td>0.991048</td>\n      <td>0.991049</td>\n      <td>468.157669</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Gaussian Naive Bayes</td>\n      <td>0.707031</td>\n      <td>0.708834</td>\n      <td>0.707031</td>\n      <td>0.707492</td>\n      <td>2.469409</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>GB Clf</td>\n      <td>0.866454</td>\n      <td>0.871475</td>\n      <td>0.866454</td>\n      <td>0.865077</td>\n      <td>190.281051</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>XGB Clf</td>\n      <td>0.990362</td>\n      <td>0.990366</td>\n      <td>0.990362</td>\n      <td>0.990363</td>\n      <td>29.083586</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### //- SUMMARY from above:\n* **Random Classifier has the best accuracy among all.** Generally RF performs the best, when models are used with not much parameter tweakings. The problem with Random forest is that, it took the maximum time among all. And if we had used the default value of n_estimators, i.e. 100, it might have taken a long span too. \n* **XGB Classifier though takes very less time, and misses the most accurate result by a whisker.** And the same is for Decision tree as well. \n* **Gradiant Boosting Classifier took a while to fit and then predict**, and it had an OKAY accuracy. Paramter tunning might improve its efficiency.\n* **LR & GNB** we so quick to predict, and **had comparatively low accuracy** as well.\n\n* I had tried to build **KNN and SVM** earlier, and it seemed like those **would take ages to fit & predict.** Those literally ran 30-40 minutes, and the fit was still in progress before I canceled and removed those two models. \n#### \n#### Let's try out now with XGB, as it was very fast. Later we can do parameter tuning on RF, XGB, DT & GB, and try and see if we can go any further than .991","metadata":{}},{"cell_type":"code","source":"#Predicting output for Original test data\nmdf_pred = xgb.predict(mdf_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:45:54.940117Z","iopub.execute_input":"2024-08-26T18:45:54.941174Z","iopub.status.idle":"2024-08-26T18:45:57.783342Z","shell.execute_reply.started":"2024-08-26T18:45:54.941132Z","shell.execute_reply":"2024-08-26T18:45:57.782163Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"display(mdf_pred)\nmdf_pred.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:46:30.221376Z","iopub.execute_input":"2024-08-26T18:46:30.221860Z","iopub.status.idle":"2024-08-26T18:46:30.232933Z","shell.execute_reply.started":"2024-08-26T18:46:30.221827Z","shell.execute_reply":"2024-08-26T18:46:30.231538Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"array([1, 0, 0, ..., 0, 1, 1])"},"metadata":{}},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(1838614,)"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Let's create a dataframe, and decode 1s and 0s back to e_label:","metadata":{}},{"cell_type":"code","source":"my_submission = pd.DataFrame({'id':test_idx, 'class':mdf_pred})\nmy_submission['class'] = my_submission['class'].map({1:'e', 0:'p'})\nmy_submission.to_csv(\"My Submission __1.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T18:52:00.463992Z","iopub.execute_input":"2024-08-26T18:52:00.464450Z","iopub.status.idle":"2024-08-26T18:52:02.623195Z","shell.execute_reply.started":"2024-08-26T18:52:00.464414Z","shell.execute_reply":"2024-08-26T18:52:02.621919Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}